{
 "metadata": {
  "name": "",
  "signature": "sha256:fb67c07689cea1b9bf7b4b6c731afa224cded8f22c0c7118418d5dda638a0b95"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "<p>In this notebook, I will do the following things: </p>\n",
      "<p>(1) Do the PCA for each partition part by Map Reduce </p>\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import pandas as pd\n",
      "import numpy as np\n",
      "import sklearn as sk\n",
      "import sys\n",
      "home_dir='/home/ubuntu/UCSD_BigData'\n",
      "sys.path.append(home_dir+'/utils')\n",
      "from find_waiting_flow import *\n",
      "from AWS_keypair_management import *"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import pickle\n",
      "Creds= pickle.load(open('/home/ubuntu/Vault/Creds.pkl','rb'))\n",
      "print Creds.keys()\n",
      "print Creds['mrjob'].keys()\n",
      "pair=Creds['mrjob']\n",
      "key_id=pair['key_id']\n",
      "secret_key=pair['secret_key']\n",
      "ID=pair['ID']\n",
      "print ID,key_id"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "['launcher', 'mrjob']\n",
        "['key_id', 'secret_key', 's3_logs', 'ID', 's3_scratch']\n",
        "lojin AKIAIQXWOHH25RD7PZ7A\n"
       ]
      }
     ],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#job_flow_id=find_waiting_flow(key_id, secret_key)\n",
      "#job_flow_id\n",
      "#job_flow_id=u'j-2KCJE554SGITB'\n",
      "#job_flow_id=u'j-2KCJE554SGITB'\n",
      "#job_flow_id=u'j-2EFV3O64LF1U2'\n",
      "#job_flow_id=u'j-G7KQYXALVHNU'\n",
      "job_flow_id=u'j-31UKS93V80CN7'\n",
      "#job_flow_id=u'j-6T8VIKMY8RHX'\n",
      "#job_flow_id=u'j-LTOJMJ14G840'\n",
      "#job_flow_id=u'j-31M986D4Y2I02'\n",
      "print job_flow_id"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "j-31UKS93V80CN7\n"
       ]
      }
     ],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "data_dir=home_dir+'/data/weather'\n",
      "!ls $data_dir"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "ALL.head.csv\t  ghcnd-stations_buffered.txt  Partition_Tree.pkl      Statistics.pkl.gz\r\n",
        "data-source.txt   ghcnd-stations.txt\t       SAMPLE_TMAX.csv\r\n",
        "ghcnd-readme.txt  ghcnd-version.txt\t       SAMPLE_TMAX.csv.old.gz\r\n"
       ]
      }
     ],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def configure_options(self):\n",
      "        super(MRWeather,self).configure_options()\n",
      "        # group file\n",
      "        self.add_file_option('--station_groups')\n",
      "        \n",
      "def mapper_init(self):        \n",
      "        group = pd.DataFrame.from_csv(self.options.station_groups)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%writefile calc_pca.py\n",
      "#!/usr/bin/python\n",
      "\"\"\"\n",
      "count the number of measurement for each year\n",
      "\"\"\"\n",
      "import sys\n",
      "sys.path.append('/usr/lib/python2.6/dist-packages')\n",
      "from mrjob.job import MRJob\n",
      "import re\n",
      "from sys import stderr\n",
      "\n",
      "class MRWeather(MRJob):\n",
      "\n",
      "    def configure_options(self):\n",
      "        super(MRWeather,self).configure_options()\n",
      "        self.add_file_option('--station_id')\n",
      "        \n",
      "    def mapper_init(self):        \n",
      "        group = pd.DataFrame.from_csv(self.options.station_id)    \n",
      "    \n",
      "    def mapper(self, _, line):\n",
      "        try:\n",
      "            self.increment_counter('MrJob Counters','mapper-all',1)\n",
      "            elements=line.split(',')\n",
      "            if elements[1] == 'TMAX':\n",
      "                number_defined=sum([e!='' for e in elements[3:]])\n",
      "                out=((elements[0], elements[2]), (elements[1], number_defined))\n",
      "                yield out\n",
      "            if elements[1] == 'TMIN':\n",
      "                number_defined=sum([e!='' for e in elements[3:]])\n",
      "                out=((elements[0], elements[2]), (elements[1], number_defined))\n",
      "                yield out\n",
      "        except Exception, e:\n",
      "            stderr.write('Error in line:\\n'+line)\n",
      "            stderr.write(e)\n",
      "            self.increment_counter('MrJob Counters','mapper-error',1)\n",
      "            out=('error',(1,1))\n",
      "        #finally:\n",
      "        #    yield out\n",
      "    \n",
      "    def reducer(self, station, counts):\n",
      "        self.increment_counter('MrJob Counters','reducer',1)\n",
      "        count = list(counts)\n",
      "        if len(count) == 2:\n",
      "            if count[0][0] == 'TMAX':\n",
      "                yield(station, (count[0][1], count[1][1]))\n",
      "            else:\n",
      "                yield(station, (count[1][1], count[0][1]))\n",
      "                \n",
      "                \n",
      "if __name__ == '__main__':\n",
      "    MRWeather.run()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!python calc_pca.py -r emr --emr-job-flow-id $job_flow_id Station_Count --station_id station_id > test"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}